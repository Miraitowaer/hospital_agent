import requests
import json
import operator
from typing import Annotated, Dict, Any, Union, Optional
from typing_extensions import TypedDict

from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage

from pydantic import BaseModel, Field, field_validator # ç¡®ä¿å¯¼å…¥äº† field_validator

# --- LangGraph æ ¸å¿ƒç»„ä»¶ ---
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver

# ==========================================
# 1. å®šä¹‰çŠ¶æ€ (State) - è¿™æ˜¯ LangGraph çš„æ ¸å¿ƒ
# ==========================================

class AgentState(TypedDict):
    # æ¶ˆæ¯å†å² (ç”¨äºè®©æ¨¡å‹ç†è§£ä¸Šä¸‹æ–‡è¯­ä¹‰)
    messages: Annotated[list, operator.add] 
    
    # ã€å…³é”®ã€‘å½“å‰çš„æŸ¥è¯¢å‚æ•°çŠ¶æ€
    # æˆ‘ä»¬æŠŠå‚æ•°å­˜åœ¨ State é‡Œï¼Œè¿™æ ·å¤šè½®å¯¹è¯å°±èƒ½è‡ªåŠ¨ç»§æ‰¿ä¸Šä¸€è½®çš„å‚æ•°ï¼
    current_params: Dict[str, Any] 
    
    # æœ€ç»ˆçš„ API ç»“æœ (JSON)
    final_result: Dict[str, Any]

# ==========================================
# 2. å®šä¹‰ Pydantic ç»“æ„ (å¤ç”¨ä½ ä¹‹å‰çš„å®šä¹‰)
# ==========================================
# ä¸ºäº†èŠ‚çœ tokenï¼Œæˆ‘ç®€åŒ–äº† descriptionï¼Œå®é™…ä½¿ç”¨è¯·ä¿ç•™ä½ è¯¦ç»†çš„ description
class TaskSearchInput(BaseModel):
    # --- æšä¸¾/ID/çŠ¶æ€ ---
    task_type: Optional[int] = Field(default=None, description="ç²¾ç¡®åŒ¹é…ä»»åŠ¡ç±»å‹ï¼š1=ä¸´æ—¶ä»»åŠ¡, 2=å›ºå®šä»»åŠ¡, 3=ç©ºç®±ä»»åŠ¡ã€‚")
    status: Optional[int] = Field(default=None, description="ç²¾ç¡®åŒ¹é…ä»»åŠ¡çŠ¶æ€ï¼š1=å·²åˆ›å»º, 2=è¿é€ä¸­, 3=å·²åˆ°è¾¾, 4=å·²å–æ¶ˆã€‚")
    task_id: Optional[int] = Field(default=None, description="ç²¾ç¡®ä»»åŠ¡IDã€‚")
    is_time_out: Optional[bool] = Field(default=None, description="æ˜¯å¦è¶…æ—¶ (True/False)ã€‚")
    is_active: Optional[bool] = Field(default=None, description="æ˜¯å¦æ¿€æ´» (True/False)ã€‚")

    # --- åç§°/æ¡ç /æ‘˜è¦ ---
    box_bar_code: Optional[str] = Field(default=None, description="ç®±å­æ¡ç ï¼Œæ”¯æŒæ¨¡ç³ŠåŒ…å«åŒ¹é…ã€‚")
    source_station_name: Optional[str] = Field(default=None, description="æºç«™ç‚¹åç§°ï¼Œæ”¯æŒæ¨¡ç³ŠåŒ¹é…ã€‚")
    dest_station_name: Optional[str] = Field(default=None, description="ç›®æ ‡ç«™ç‚¹åç§°ï¼Œæ”¯æŒæ¨¡ç³ŠåŒ¹é…ã€‚")
    summary: Optional[str] = Field(default=None, description="ä»»åŠ¡æ‘˜è¦/å¤‡æ³¨ï¼Œæ”¯æŒæ¨¡ç³ŠåŒ¹é…ã€‚")
    source_station_id: Optional[int] = Field(default=None, description="æºç«™ç‚¹IDã€‚")
    dest_station_id: Optional[int] = Field(default=None, description="ç›®æ ‡ç«™ç‚¹IDã€‚")

    # --- æ—¶é—´èŒƒå›´ ---
    create_date_from: Optional[str] = Field(default=None, description="åˆ›å»ºæ—¶é—´èŒƒå›´-èµ·å§‹ã€‚")
    create_date_to: Optional[str] = Field(default=None, description="åˆ›å»ºæ—¶é—´èŒƒå›´-ç»“æŸã€‚")
    task_start_time_from: Optional[str] = Field(default=None, description="ä»»åŠ¡å®é™…å¼€å§‹æ—¶é—´-èµ·å§‹ã€‚")
    task_start_time_to: Optional[str] = Field(default=None, description="ä»»åŠ¡å®é™…å¼€å§‹æ—¶é—´-ç»“æŸã€‚")
    task_finish_time_from: Optional[str] = Field(default=None, description="ä»»åŠ¡å®Œæˆæ—¶é—´-èµ·å§‹ã€‚")
    task_finish_time_to: Optional[str] = Field(default=None, description="ä»»åŠ¡å®Œæˆæ—¶é—´-ç»“æŸã€‚")

    # --- æ•°å€¼èŒƒå›´ ---
    min_consume_time: Optional[int] = Field(default=None, description="æœ€å°æ¶ˆè€—æ—¶é—´(ç§’)ã€‚")
    max_consume_time: Optional[int] = Field(default=None, description="æœ€å¤§æ¶ˆè€—æ—¶é—´(ç§’)ã€‚")
    min_estimated_time: Optional[int] = Field(default=None, description="æœ€å°é¢„ä¼°æ—¶é—´(ç§’)ã€‚")
    max_estimated_time: Optional[int] = Field(default=None, description="æœ€å¤§é¢„ä¼°æ—¶é—´(ç§’)ã€‚")

    # --- åˆ†é¡µ ---
    page: int = Field(default=1, description="é¡µç ï¼Œé»˜è®¤ä¸º1ã€‚")
    size: int = Field(default=10, description="æ¯é¡µå¤§å°ï¼Œé»˜è®¤ä¸º10ã€‚")

    @field_validator('*', mode='before')
    @classmethod
    def parse_nested_dict(cls, v: Any) -> Any:
        # æ£€æŸ¥æ˜¯å¦æ˜¯å­—å…¸
        if isinstance(v, dict):
            # æƒ…å†µ 1: æ¨¡å‹è¿”å›äº† {'value': 1} -> æ‹†åŒ…å–å€¼
            if 'value' in v:
                return v['value']
            
            # æƒ…å†µ 2: æ¨¡å‹è¿”å›äº† {} (ç©ºå­—å…¸) -> è§†ä¸º None (å³æœªæå–åˆ°æœ‰æ•ˆå€¼)
            # è¿™å°±æ˜¯è§£å†³ä½ å½“å‰æŠ¥é”™çš„å…³é”®
            if not v:
                return None
            
            # æƒ…å†µ 3: å…¶ä»–å¥‡æ€ªçš„å­—å…¸ -> ä¸ºäº†ä¸å´©ï¼Œç»Ÿä¸€è½¬ None
            return None
            
        # ä¸æ˜¯å­—å…¸ï¼Œç›´æ¥è¿”å›ï¼ˆæ¯”å¦‚å·²ç»æ˜¯æ­£å¸¸çš„ int æˆ– strï¼‰
        return v

# ==========================================
# 3. å®šä¹‰èŠ‚ç‚¹é€»è¾‘ (Nodes)
# ==========================================

# --- èŠ‚ç‚¹ A: å‚æ•°æå–ä¸åˆå¹¶ ---
def extract_params_node(state: AgentState):
    """
    å‚æ•°æå–èŠ‚ç‚¹
    ä¼˜åŒ–ç­–ç•¥ï¼šåªå‘é€ç”¨æˆ·æœ€æ–°çš„ä¸€æ¡æŒ‡ä»¤ç»™æ¨¡å‹ï¼Œé¿å…å†å²å¯¹è¯å¹²æ‰°æ¨¡å‹çš„åˆ¤æ–­ã€‚
    """
    llm = ChatOpenAI(
        model="/model/qwen3-235b-a22b",
        openai_api_base="https://aimpapi.midea.com/t-aigc/aimp-qwen3-235b-a22b/v1",
        openai_api_key="msk-9e80428b8a8e4baa47e44ccb8dc96c4e1e59a80a0f2001b0d6efa63ed7b8ea76",
        temperature=0.01,
        # å¼ºåˆ¶å¼€å¯æ€è€ƒæ¨¡å¼ï¼Œæœ‰åŠ©äºå¤æ‚é€»è¾‘æ¨ç†
        extra_body={"chat_template_kwargs": {"enable_thinking": True}}
    )
    
    # ç»‘å®š Pydantic ç»“æ„
    structured_llm = llm.with_structured_output(TaskSearchInput)
    
    # è·å–å½“å‰å‚æ•°
    current_p = state.get("current_params", {})
    
    # è·å–ç”¨æˆ·æœ€æ–°çš„ä¸€æ¡è¾“å…¥
    # state["messages"] åŒ…å«äº†æ‰€æœ‰çš„å¯¹è¯å†å²ï¼Œæˆ‘ä»¬åªå–æœ€åä¸€æ¡ HumanMessage
    last_message = state["messages"][-1]
    
    # æ„é€ æ›´å…·æœ‰æŒ‡å‘æ€§çš„ System Prompt
    system_prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªçŠ¶æ€æ›´æ–°å™¨ã€‚ä½ ç»´æŠ¤ç€ä¸€ç»„æŸ¥è¯¢å‚æ•°ã€‚
    
    ã€å½“å‰ç”Ÿæ•ˆå‚æ•°ã€‘ï¼š
    {json.dumps(current_p, ensure_ascii=False)}
    
    ã€ç”¨æˆ·æœ€æ–°æŒ‡ä»¤ã€‘ï¼š
    "{last_message.content}"
    
    è¯·æ ¹æ®ç”¨æˆ·çš„æŒ‡ä»¤ï¼Œè¾“å‡ºéœ€è¦ã€ä¿®æ”¹æˆ–æ–°å¢ã€‘çš„å‚æ•°ï¼š
    1. å¦‚æœç”¨æˆ·è¯´â€œå·²è¶…æ—¶çš„â€ï¼Œè¯·è¾“å‡º {{"is_time_out": true}}ã€‚
    2. å¦‚æœç”¨æˆ·è¯´â€œä¸è¦è¶…æ—¶çš„â€ï¼Œè¯·è¾“å‡º {{"is_time_out": false}}ã€‚
    3. å¦‚æœç”¨æˆ·è¯´â€œå»æ‰è¶…æ—¶æ¡ä»¶â€ï¼Œè¯·è¾“å‡º {{"is_time_out": null}}ã€‚
    4. å¯¹äºç”¨æˆ·ã€æœªæåŠã€‘çš„æ¡ä»¶ï¼Œè¯·ä¸è¦è¾“å‡ºï¼ˆå³è¿”å› nullï¼‰ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨ä¿ç•™åŸå€¼ã€‚
    """
    
    # å…³é”®ä¿®æ”¹ï¼šåªå‘ System Promptï¼Œä¸å‘å†å² messages
    # è¿™æ ·æ¨¡å‹å°±ä¸ä¼šè¢«ä¹‹å‰çš„å¯¹è¯å¹²æ‰°ï¼Œåªä¸“æ³¨å¤„ç†å½“å‰è¿™ä¸€å¥
    messages = [SystemMessage(content=system_prompt)]
    
    # è°ƒç”¨æ¨¡å‹
    try:
        new_params_obj = structured_llm.invoke(messages)
        
        # ä½¿ç”¨ model_dump(exclude_none=True) è¿‡æ»¤æ‰æ¨¡å‹æ²¡å¡«çš„å­—æ®µ
        new_params_dict = new_params_obj.model_dump(exclude_none=True)
        
        # --- è°ƒè¯•æ—¥å¿— (å…³é”®) ---
        print(f"\n[Debug] ç”¨æˆ·æŒ‡ä»¤: {last_message.content}")
        print(f"[Debug] æ¨¡å‹æå–ç»“æœ (Raw): {new_params_dict}")
        # ---------------------

        # åˆå¹¶å‚æ•°ï¼šæ—§å‚æ•° update æ–°å‚æ•°
        merged_params = current_p.copy()
        merged_params.update(new_params_dict)
        
        return {
            "current_params": merged_params
        }
        
    except Exception as e:
        print(f"\n[Error] å‚æ•°æå–å¤±è´¥: {e}")
        # å¦‚æœå‡ºé”™ï¼Œä¿æŒå‚æ•°ä¸å˜
        return {"current_params": current_p}

# --- èŠ‚ç‚¹ B: API è°ƒç”¨ (Data Fetcher) ---
def fetch_data_node(state: AgentState):
    """
    è¿™ä¸ªèŠ‚ç‚¹çš„ä½œç”¨ï¼šçº¯ç²¹çš„æ‰§è¡Œã€‚
    æ‹¿åˆ° state['current_params'] -> è°ƒç”¨ requests -> å­˜å…¥ state['final_result']
    """
    params = state["current_params"]
    print(f"  >>> [APIæ‰§è¡Œ] æœ€ç»ˆè¯·æ±‚å‚æ•°: {params}")
    
    # 1. å‚æ•°æ˜ å°„ (Snake -> Pascal)
    # è¿™é‡Œå¤ç”¨ä½ ä¹‹å‰çš„æ˜ å°„é€»è¾‘
    param_mapping = {
            "task_type": "TaskType", "status": "Status", "task_id": "Id",
            "is_time_out": "IsTimeOut", "is_active": "IsActive",
            "box_bar_code": "BoxBarCode", "source_station_name": "SourceStationName",
            "dest_station_name": "DestStationName", "summary": "Summary",
            "source_station_id": "SourceStationId", "dest_station_id": "DestStationId",
            "create_date_from": "CreateDateFrom", "create_date_to": "CreateDateTo",
            "task_start_time_from": "TaskStartTimeFrom", "task_start_time_to": "TaskStartTimeTo",
            "task_finish_time_from": "TaskFinishTimeFrom", "task_finish_time_to": "TaskFinishTimeTo",
            "min_consume_time": "MinConsumeTime", "max_consume_time": "MaxConsumeTime",
            "min_estimated_time": "MinEstimatedTime", "max_estimated_time": "MaxEstimatedTime",
            "page": "page", "size": "size"
        }
    
    api_params = {}
    for k, v in params.items():
        if v is not None:
            api_key = param_mapping.get(k, k)
            api_params[api_key] = v

    # 2. å‘èµ·è¯·æ±‚
    url = "http://106.15.57.43:8848/api/AI/Task"

    try:
        resp = requests.get(url, params=api_params, timeout=10)
        data = resp.json()
    except Exception as e:
        data = {"error": str(e)}
        
    # 3. æ›´æ–° State
    return {"final_result": data}

# ==========================================
# 4. æ„å»ºå›¾ (Graph Construction)
# ==========================================

def build_graph():
    workflow = StateGraph(AgentState)

    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("extract_params", extract_params_node)
    workflow.add_node("fetch_data", fetch_data_node)

    # å®šä¹‰æµç¨‹
    # Start -> extract_params -> fetch_data -> End
    workflow.set_entry_point("extract_params")
    workflow.add_edge("extract_params", "fetch_data")
    workflow.add_edge("fetch_data", END)

    # è®¾ç½®è®°å¿† (Checkpointer)
    # è¿™ä½¿å¾— graph.invoke å¯ä»¥ä¼ å…¥ thread_id æ¥æ¢å¤çŠ¶æ€
    memory = MemorySaver()
    
    return workflow.compile(checkpointer=memory)

# ==========================================
# 5. è¿è¡Œæµ‹è¯•
# ==========================================

if __name__ == "__main__":
    app = build_graph()
    
    # 2. é…ç½®çº¿ç¨‹ ID 
    # å›ºå®šè¿™ä¸ª IDï¼Œå°±èƒ½åœ¨å½“å‰è¿è¡ŒæœŸé—´ä¿æŒå¤šè½®å¯¹è¯è®°å¿†
    # æ¯æ¬¡é‡æ–°è¿è¡Œè„šæœ¬ï¼Œè®°å¿†ä¼šé‡ç½®ï¼ˆå› ä¸ºç”¨çš„æ˜¯ MemorySaver å†…å­˜å­˜å‚¨ï¼‰
    thread_id = "console_user_001"
    config = {"configurable": {"thread_id": thread_id}}
    
    print("="*50)
    print("ğŸ¥ æ™ºèƒ½è°ƒåº¦åŠ©æ‰‹ - å‘½ä»¤è¡Œäº¤äº’æ¨¡å¼")
    print(f"å½“å‰ä¼šè¯ ID: {thread_id}")
    print("æç¤ºï¼šè¾“å…¥ 'q', 'quit', 'exit' å¯é€€å‡ºç¨‹åº")
    print("="*50)

    # æŸ¥è¯¢ç¥ç»å†…ç§‘åˆ°é™é…ä¸­å¿ƒçš„å·²åˆ°è¾¾çš„ä¸´æ—¶ä»»åŠ¡
    # æŸ¥è¯¢ä¸‹è¿™äº›ä»»åŠ¡å½“ä¸­çš„è¶…æ—¶ä»»åŠ¡

    while True:
        try:
            # A. è·å–ç”¨æˆ·è¾“å…¥
            user_query = input("\nğŸ‘‰ è¯·è¾“å…¥æŒ‡ä»¤: ").strip()
            
            # B. æ£€æŸ¥é€€å‡ºæ¡ä»¶
            if user_query.lower() in ["q", "quit", "exit"]:
                print("\nğŸ‘‹ ç¨‹åºå·²é€€å‡ºï¼Œå†è§ï¼")
                break
            
            if not user_query:
                continue

            # C. æ„é€  Graph è¾“å…¥
            # LangGraph éœ€è¦ä¸€ä¸ª messages åˆ—è¡¨ä½œä¸ºè¾“å…¥
            inputs = {"messages": [HumanMessage(content=user_query)]}
            
            # D. æ‰§è¡Œè°ƒç”¨
            # print("   (æ­£åœ¨è¯·æ±‚ API...)") # å¯é€‰ï¼šåŠ ä¸ªåŠ è½½æç¤º
            final_state = app.invoke(inputs, config=config)
            
            # E. æ‰“å°çº¯ JSON ç»“æœ
            result = final_state.get("final_result", {})
            
            print("\nğŸ¤– [API JSON å“åº”]:")
            print(json.dumps(result, ensure_ascii=False, indent=2))
            
        except KeyboardInterrupt:
            # æ•è· Ctrl+C
            print("\n\nğŸ‘‹ ç”¨æˆ·å¼ºåˆ¶ä¸­æ–­")
            break
        except Exception as e:
            print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")