import requests
import json
import operator
from typing import Annotated, Dict, Any, Literal, Optional
from typing_extensions import TypedDict

from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage
from pydantic import BaseModel, Field, field_validator

from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver

# ==========================================
# 1. å®šä¹‰çŠ¶æ€ (State)
# ==========================================
class AgentState(TypedDict):
    messages: Annotated[list, operator.add] 
    current_params: Dict[str, Any] 
    final_result: Dict[str, Any]
    # æ–°å¢ï¼šç”¨äºåœ¨èŠ‚ç‚¹é—´ä¼ é€’æ„å›¾
    intent: Literal["NEW_QUERY", "REFINE_QUERY"]

# ==========================================
# 2. å®šä¹‰ Pydantic ç»“æ„
# ==========================================

# --- A. ä¸“é—¨ç”¨äºæ„å›¾åˆ†ç±»çš„ç®€å•ç»“æ„ ---
class IntentOutput(BaseModel):
    intent: Literal["NEW_QUERY", "REFINE_QUERY"] = Field(
        description="""
        ç”¨æˆ·æ„å›¾åˆ†ç±»ï¼š
        - NEW_QUERY: å…¨æ–°æŸ¥è¯¢ã€‚ç”¨æˆ·å‘èµ·ä¸€ä¸ªå®Œå…¨ä¸åŒçš„ä»»åŠ¡ï¼Œæˆ–è€…æ˜ç¡®è¡¨ç¤º'ä¸æŸ¥é‚£ä¸ªäº†'ã€'é‡æ–°æŸ¥'ã€‚
        - REFINE_QUERY: è¿½åŠ /ä¿®æ”¹ã€‚ç”¨æˆ·åœ¨å½“å‰åŸºç¡€ä¸Šå¢åŠ æ¡ä»¶ï¼ˆå¦‚'åªè¦è¶…æ—¶çš„'ï¼‰æˆ–ä¿®æ”¹æ¡ä»¶ï¼ˆå¦‚'æ”¹æŸ¥Aç«™ç‚¹çš„'ï¼‰ã€‚
        """
    )

# --- B. ä¸“é—¨ç”¨äºå‚æ•°æå–çš„ç»“æ„ (å›å½’çº¯ç²¹) ---
# ä¸éœ€è¦å†å»å®šä¹‰ search_intent å­—æ®µäº†ï¼Œä¸“å¿ƒå®šä¹‰ä¸šåŠ¡å­—æ®µ
class TaskSearchInput(BaseModel):
    # --- æšä¸¾/ID/çŠ¶æ€ ---
    task_type: Optional[int] = Field(default=None, description="ç²¾ç¡®åŒ¹é…ä»»åŠ¡ç±»å‹ï¼š1=ä¸´æ—¶ä»»åŠ¡, 2=å›ºå®šä»»åŠ¡, 3=ç©ºç®±ä»»åŠ¡ã€‚")
    status: Optional[int] = Field(default=None, description="ç²¾ç¡®åŒ¹é…ä»»åŠ¡çŠ¶æ€ï¼š1=å·²åˆ›å»º, 2=è¿é€ä¸­, 3=å·²åˆ°è¾¾, 4=å·²å–æ¶ˆã€‚")
    task_id: Optional[int] = Field(default=None, description="ç²¾ç¡®ä»»åŠ¡IDã€‚")
    is_time_out: Optional[bool] = Field(default=None, description="æ˜¯å¦è¶…æ—¶ (True/False)ã€‚")
    is_active: Optional[bool] = Field(default=None, description="æ˜¯å¦æ¿€æ´» (True/False)ã€‚")

    # --- åç§°/æ¡ç /æ‘˜è¦ ---
    box_bar_code: Optional[str] = Field(default=None, description="ç®±å­æ¡ç ï¼Œæ”¯æŒæ¨¡ç³ŠåŒ…å«åŒ¹é…ã€‚")
    source_station_name: Optional[str] = Field(default=None, description="æºç«™ç‚¹åç§°ï¼Œæ”¯æŒæ¨¡ç³ŠåŒ¹é…ã€‚")
    dest_station_name: Optional[str] = Field(default=None, description="ç›®æ ‡ç«™ç‚¹åç§°ï¼Œæ”¯æŒæ¨¡ç³ŠåŒ¹é…ã€‚")
    summary: Optional[str] = Field(default=None, description="ä»»åŠ¡æ‘˜è¦/å¤‡æ³¨ï¼Œæ”¯æŒæ¨¡ç³ŠåŒ¹é…ã€‚")
    source_station_id: Optional[int] = Field(default=None, description="æºç«™ç‚¹IDã€‚")
    dest_station_id: Optional[int] = Field(default=None, description="ç›®æ ‡ç«™ç‚¹IDã€‚")

    # --- æ—¶é—´èŒƒå›´ ---
    create_date_from: Optional[str] = Field(default=None, description="åˆ›å»ºæ—¶é—´èŒƒå›´-èµ·å§‹ã€‚")
    create_date_to: Optional[str] = Field(default=None, description="åˆ›å»ºæ—¶é—´èŒƒå›´-ç»“æŸã€‚")
    task_start_time_from: Optional[str] = Field(default=None, description="ä»»åŠ¡å®é™…å¼€å§‹æ—¶é—´-èµ·å§‹ã€‚")
    task_start_time_to: Optional[str] = Field(default=None, description="ä»»åŠ¡å®é™…å¼€å§‹æ—¶é—´-ç»“æŸã€‚")
    task_finish_time_from: Optional[str] = Field(default=None, description="ä»»åŠ¡å®Œæˆæ—¶é—´-èµ·å§‹ã€‚")
    task_finish_time_to: Optional[str] = Field(default=None, description="ä»»åŠ¡å®Œæˆæ—¶é—´-ç»“æŸã€‚")

    # --- æ•°å€¼èŒƒå›´ ---
    min_consume_time: Optional[int] = Field(default=None, description="æœ€å°æ¶ˆè€—æ—¶é—´(ç§’)ã€‚")
    max_consume_time: Optional[int] = Field(default=None, description="æœ€å¤§æ¶ˆè€—æ—¶é—´(ç§’)ã€‚")
    min_estimated_time: Optional[int] = Field(default=None, description="æœ€å°é¢„ä¼°æ—¶é—´(ç§’)ã€‚")
    max_estimated_time: Optional[int] = Field(default=None, description="æœ€å¤§é¢„ä¼°æ—¶é—´(ç§’)ã€‚")

    # --- åˆ†é¡µ ---
    page: int = Field(default=1, description="é¡µç ï¼Œé»˜è®¤ä¸º1ã€‚")
    size: int = Field(default=10, description="æ¯é¡µå¤§å°ï¼Œé»˜è®¤ä¸º10ã€‚")

    # =========================================================
    # ã€ä¿®å¤æ ¸å¿ƒã€‘å‡çº§ç‰ˆæ¸…æ´—å™¨ï¼šè‡ªåŠ¨å¤„ç† List å’Œ Dict
    # =========================================================
    @field_validator('*', mode='before')
    @classmethod
    def preprocess_input(cls, v: Any) -> Any:
        # 1. å¤„ç†åˆ—è¡¨æƒ…å†µ (è§£å†³ä½ ç°åœ¨çš„æŠ¥é”™)
        if isinstance(v, list):
            # å¦‚æœæ˜¯ç©ºåˆ—è¡¨ [] -> è¿”å› None
            if not v:
                return None
            # å¦‚æœæ˜¯ ['ç¥ç»å†…ç§‘'] -> å–å‡º 'ç¥ç»å†…ç§‘'
            return v[0]

        # 2. å¤„ç†å­—å…¸æƒ…å†µ (è§£å†³ä¹‹å‰çš„ {'value': 1} é—®é¢˜)
        if isinstance(v, dict):
            if 'value' in v:
                return v['value']
            if not v:
                return None
            return None
            
        # 3. æ­£å¸¸å€¼ç›´æ¥è¿”å›
        return v

# ==========================================
# 3. å®šä¹‰èŠ‚ç‚¹ (Nodes) - èŒè´£åˆ†ç¦»
# ==========================================

# --- èŠ‚ç‚¹ 1: æ„å›¾åˆ†ç±»å™¨ (Router) ---
def intent_classifier_node(state: AgentState):
    """
    åªåšä¸€ä»¶äº‹ï¼šåˆ¤æ–­æ˜¯æ–°æŸ¥è¯¢è¿˜æ˜¯è€æŸ¥è¯¢ã€‚
    """
    llm = ChatOpenAI(
        model="/model/DeepSeek-R1",
        openai_api_base="https://aimpapi.midea.com/t-aigc/aimp-deepseek-r1/v1",
        openai_api_key="msk-ca04571203246b31eec2dae635521ea079ca23818fdbe1f2177e17934382d378",
        temperature=0.01
        # extra_body={"chat_template_kwargs": {"enable_thinking": True}}
    )
    
    # ç»‘å®šç®€å•çš„ IntentOutput
    classifier = llm.with_structured_output(IntentOutput)
    
    last_user_msg = state["messages"][-1].content
    
    # æç®€ Promptï¼Œæ²¡æœ‰ä»»ä½•å‚æ•°å¹²æ‰°
    prompt = f"""
    è¯·åˆ†æç”¨æˆ·çš„æœ€æ–°æŒ‡ä»¤ï¼š"{last_user_msg}"
    
    åˆ¤æ–­ä»–æ˜¯æƒ³åœ¨ã€ç°æœ‰æŸ¥è¯¢åŸºç¡€ä¸Šä¿®æ”¹æ¡ä»¶ã€‘ï¼Œè¿˜æ˜¯ã€å‘èµ·ä¸€ä¸ªå…¨æ–°çš„æŸ¥è¯¢ã€‘ï¼Ÿ
    å¦‚æœè¯é¢˜å®Œå…¨åˆ‡æ¢ï¼ˆä¾‹å¦‚ä»'æŸ¥ä»»åŠ¡'å˜æˆ'æŸ¥ç«™ç‚¹'ï¼Œæˆ–è€…ä»'æŸ¥ç¥ç»å†…ç§‘'å˜æˆ'æŸ¥æ‰€æœ‰ä»»åŠ¡'ï¼‰ï¼Œè¯·åˆ¤å®šä¸º NEW_QUERYã€‚
    """
    
    try:
        result = classifier.invoke([SystemMessage(content=prompt)])
        intent = result.intent
    except:
        intent = "REFINE_QUERY" # é»˜è®¤ä¿å®ˆç­–ç•¥
        
    print(f"\n--------- ğŸ§  æ„å›¾åˆ¤æ–­: {intent} ---------")
    return {"intent": intent}


# --- èŠ‚ç‚¹ 2: çŠ¶æ€æ¸…æ´—å™¨ (Cleaner) ---
def state_cleaner_node(state: AgentState):
    """
    åªåšä¸€ä»¶äº‹ï¼šæ¸…ç©º current_paramsï¼Œé‡ç½®ä¸ºé»˜è®¤å€¼ã€‚
    """
    print("   -> [åŠ¨ä½œ] æ£€æµ‹åˆ°æ–°è¯é¢˜ï¼Œæ­£åœ¨æ¸…é™¤å†å²å‚æ•°...")
    return {
        "current_params": {"page": 1, "size": 10} # æ¢å¤å‡ºå‚è®¾ç½®
    }


# --- èŠ‚ç‚¹ 3: å‚æ•°æå–å™¨ (Extractor) ---
def extract_params_node(state: AgentState):
    """
    åªåšä¸€ä»¶äº‹ï¼šæå–å‚æ•°å¹¶åˆå¹¶ã€‚
    å®ƒæ ¹æœ¬ä¸ç”¨ç®¡'æ˜¯ä¸æ˜¯æ–°æŸ¥è¯¢'ï¼Œå› ä¸ºå®ƒæ‹¿åˆ°çš„ current_params å·²ç»è¢«ä¸Šæ¸¸èŠ‚ç‚¹å¤„ç†è¿‡äº†ã€‚
    å¦‚æœæ˜¯æ–°æŸ¥è¯¢ï¼Œå®ƒæ‹¿åˆ°çš„å°±æ˜¯ç©ºçš„ï¼Œè‡ªç„¶å°±åªæå–æ–°å‚æ•°ã€‚
    """
    llm = ChatOpenAI(
        model="/model/DeepSeek-R1",
        openai_api_base="https://aimpapi.midea.com/t-aigc/aimp-deepseek-r1/v1",
        openai_api_key="msk-ca04571203246b31eec2dae635521ea079ca23818fdbe1f2177e17934382d378",
        temperature=0.01
        # extra_body={"chat_template_kwargs": {"enable_thinking": True}}
    )
    
    structured_llm = llm.with_structured_output(TaskSearchInput)
    
    current_p = state.get("current_params", {})
    # å…œåº•ï¼šå¦‚æœå‰åºèŠ‚ç‚¹æ²¡åˆå§‹åŒ–ï¼Œè¿™é‡Œåˆå§‹åŒ–
    if not current_p: current_p = {"page": 1, "size": 10}

    last_msg = state["messages"][-1].content
    
    # Prompt åªéœ€è¦å…³æ³¨æå–
    system_prompt = f"""
    å½“å‰ç”Ÿæ•ˆå‚æ•°ï¼š{json.dumps(current_p, ensure_ascii=False)}
    
    ç”¨æˆ·æŒ‡ä»¤ï¼š"{last_msg}"
    
    è¯·è¾“å‡ºéœ€è¦å˜æ›´çš„å‚æ•°ï¼ˆå¢é‡ï¼‰ã€‚
    æ³¨æ„ï¼š
    1. æå–æ˜ç¡®æåˆ°çš„æ¡ä»¶ã€‚
    2. å¦‚æœç”¨æˆ·è¯´â€œå»æ‰/ä¸é™â€ï¼Œè¯·è¾“å‡º nullã€‚
    """
    
    try:
        res = structured_llm.invoke([SystemMessage(content=system_prompt)])
        # exclude_unset=True ä¾ç„¶é‡è¦ï¼Œç”¨äºå¤„ç†æ¸…é™¤é€»è¾‘
        delta = res.model_dump(exclude_unset=True)
        
        print(f"[Debug] æå–å¢é‡: {delta}")
        
        # åˆå¹¶
        merged = current_p.copy()
        for k, v in delta.items():
            if v is None:
                if k in merged: del merged[k]
            else:
                merged[k] = v
        
        # å†æ¬¡å…œåº•åˆ†é¡µ
        if "page" not in merged: merged["page"] = 1
        if "size" not in merged: merged["size"] = 10
        
        return {"current_params": merged}
        
    except Exception as e:
        print(f"[Error] æå–å¤±è´¥: {e}")
        return {"current_params": current_p}


# --- èŠ‚ç‚¹ 4: æ•°æ®è¯·æ±‚å™¨ (Fetcher) ---
def fetch_data_node(state: AgentState):
    params = state["current_params"]
    print(f"  >>> [APIæ‰§è¡Œ] å‚æ•°: {params}")
    
    # ç®€åŒ–çš„è¯·æ±‚é€»è¾‘ï¼Œå¤ç”¨ä½ ä¹‹å‰çš„ mapping
    param_mapping = {
        "task_type": "TaskType", "status": "Status", "is_time_out": "IsTimeOut",
        "is_active": "IsActive", "source_station_name": "SourceStationName",
        "dest_station_name": "DestStationName", "page": "page", "size": "size"
    }
    
    api_params = {}
    for k, v in params.items():
        if v is not None:
            api_params[param_mapping.get(k, k)] = v

    url = "http://106.15.57.43:8848/api/AI/Task"
    try:
        resp = requests.get(url, params=api_params, timeout=5)
        data = resp.json()
    except Exception as e:
        data = {"error": str(e)}
        
    return {"final_result": data}


# ==========================================
# 4. æ„å»ºå›¾ (Topology) - æ ¸å¿ƒæ”¹åŠ¨
# ==========================================

def route_intent(state: AgentState):
    """æ¡ä»¶è·¯ç”±é€»è¾‘"""
    if state["intent"] == "NEW_QUERY":
        return "cleaner"
    else:
        return "extractor"

def build_graph():
    workflow = StateGraph(AgentState)

    # æ³¨å†ŒèŠ‚ç‚¹
    workflow.add_node("classifier", intent_classifier_node)
    workflow.add_node("cleaner", state_cleaner_node) # æ–°å¢æ¸…æ´—èŠ‚ç‚¹
    workflow.add_node("extractor", extract_params_node)
    workflow.add_node("fetcher", fetch_data_node)

    # å®šä¹‰æµç¨‹å›¾
    # 1. å…¥å£ -> åˆ†ç±»å™¨
    workflow.set_entry_point("classifier")
    
    # 2. åˆ†ç±»å™¨ -> æ¡ä»¶åˆ†æ”¯ (æ˜¯å¦å»æ¸…æ´—)
    workflow.add_conditional_edges(
        "classifier",
        route_intent,
        {
            "cleaner": "cleaner",   # èµ°æ¸…æ´—è·¯çº¿
            "extractor": "extractor" # èµ°ä¿ç•™è·¯çº¿
        }
    )
    
    # 3. æ¸…æ´—å™¨ -> æå–å™¨ (æ´—å®Œåï¼Œå½“ä½œç™½çº¸ç»§ç»­æå–)
    workflow.add_edge("cleaner", "extractor")
    
    # 4. æå–å™¨ -> è¯·æ±‚å™¨
    workflow.add_edge("extractor", "fetcher")
    
    # 5. è¯·æ±‚å™¨ -> ç»“æŸ
    workflow.add_edge("fetcher", END)

    memory = MemorySaver()
    return workflow.compile(checkpointer=memory)


if __name__ == "__main__":
    app = build_graph()
    config = {"configurable": {"thread_id": "router_demo_01"}}
    
    print("="*40)
    print("ğŸš€ æ™ºèƒ½è°ƒåº¦åŠ©æ‰‹ (Router + Cleaner æ¶æ„)")
    print("="*40)

    # æŸ¥è¯¢ç¥ç»å†…ç§‘åˆ°é™é…ä¸­å¿ƒçš„å·²åˆ°è¾¾çš„ä¸´æ—¶ä»»åŠ¡
    # æŸ¥è¯¢ä¸‹è¿™äº›ä»»åŠ¡å½“ä¸­çš„è¶…æ—¶ä»»åŠ¡

    while True:
        q = input("\nğŸ‘‰ æŒ‡ä»¤: ").strip()
        if q in ["q", "exit"]: break
        if not q: continue
        
        inputs = {"messages": [HumanMessage(content=q)]}
        res = app.invoke(inputs, config=config)
        
        print(f"ğŸ¤– ç»“æœ: {json.dumps(res['final_result'], ensure_ascii=False, indent=2)}")